{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Exp-05]RockPaperScissors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 라이브러리 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-02 21:53:35.022373: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-08-02 21:53:35.022396: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.1\n",
      "1.23.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "print(tf.__version__)\n",
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 불러오고 Resize 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_images(img_path):\n",
    "\timages=glob.glob(img_path + \"/*.jpg\")  \n",
    "    \n",
    "\tprint(len(images), \" images to be resized.\")\n",
    "\n",
    "    # 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "\ttarget_size=(28,28)\n",
    "\tfor img in images:\n",
    "\t\told_img=Image.open(img)\n",
    "\t\tnew_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "\t\tnew_img.save(img, \"JPEG\")\n",
    "    \n",
    "\tprint(len(images), \" images resized.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100  images to be resized.\n",
      "100  images resized.\n",
      "100  images to be resized.\n",
      "100  images resized.\n",
      "100  images to be resized.\n",
      "100  images resized.\n"
     ]
    }
   ],
   "source": [
    "# 가위 바위 보 이미지 불러와서 resize하기\n",
    "image_dir_path1 = os.getenv(\"HOME\") + \"/Code/Exploration Submit/5/train1/scissor\"\n",
    "resize_images(image_dir_path1)\n",
    "\n",
    "image_dir_path2 = os.getenv(\"HOME\") + \"/Code/Exploration Submit/5/train1/rock\"\n",
    "resize_images(image_dir_path2)\n",
    "\n",
    "image_dir_path3 = os.getenv(\"HOME\") + \"/Code/Exploration Submit/5/train1/paper\"\n",
    "resize_images(image_dir_path3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train 데이터 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 300 입니다.\n",
      "x_train shape: (300, 28, 28, 3)\n",
      "y_train shape: (300,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_data(img_path, number_of_data=300):  # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1  \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터(x_train)의 이미지 개수는\", idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/Code/Exploration Submit/5/train1\"\n",
    "(x_train, y_train)=load_data(image_dir_path)\n",
    "x_train_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_train shape: {}\".format(x_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "300개의 28x28x3(rgb) 입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이미지 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "라벨:  0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train_norm[0])\n",
    "print('라벨: ', y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28, 3)\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(x_train_norm[0].shape)\n",
    "print(y_train[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 딥러닝 네트워크 설계하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 기존의 채널 1개에서 3개로 증가\n",
    "* 최종 class의 개수가 10 -> 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 13, 13, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 5, 5, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1600)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                51232     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 70,723\n",
      "Trainable params: 70,723\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-02 21:53:37.449383: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-02 21:53:37.449709: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-08-02 21:53:37.449747: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2022-08-02 21:53:37.449781: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2022-08-02 21:53:37.449864: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2022-08-02 21:53:37.449938: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2022-08-02 21:53:37.449983: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2022-08-02 21:53:37.450022: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2022-08-02 21:53:37.450053: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-08-02 21:53:37.450060: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-08-02 21:53:37.450660: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "# model을 직접 만들어 보세요.\n",
    "# Hint! model의 입력/출력부에 특히 유의해 주세요. 가위바위보 데이터셋은 MNIST 데이터셋과 어떤 점이 달라졌나요?\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(64, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(32, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 딥러닝 네트워크 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 28, 28, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_norm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.0979 - accuracy: 0.2967\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 1.0008 - accuracy: 0.6233\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.8581 - accuracy: 0.7533\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.6644 - accuracy: 0.7800\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4477 - accuracy: 0.9033\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.2673 - accuracy: 0.9667\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.1916 - accuracy: 0.9567\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.1059 - accuracy: 0.9967\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0740 - accuracy: 0.9967\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0507 - accuracy: 0.9967\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc03824e4d0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train_norm, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 성능 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "성능 확인을 위해 test data를 만들어 봅시다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test 이미지를 resize 합시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100  images to be resized.\n",
      "100  images resized.\n",
      "100  images to be resized.\n",
      "100  images resized.\n",
      "100  images to be resized.\n",
      "100  images resized.\n"
     ]
    }
   ],
   "source": [
    "test_image_dir_path1 = os.getenv(\"HOME\") + \"/Code/Exploration Submit/5/test/scissor\"\n",
    "resize_images(test_image_dir_path1)\n",
    "\n",
    "test_image_dir_path2 = os.getenv(\"HOME\") + \"/Code/Exploration Submit/5/test/rock\"\n",
    "resize_images(test_image_dir_path2)\n",
    "\n",
    "test_image_dir_path3 = os.getenv(\"HOME\") + \"/Code/Exploration Submit/5/test/paper\"\n",
    "resize_images(test_image_dir_path3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 300 입니다.\n"
     ]
    }
   ],
   "source": [
    "test_image_dir_path = os.getenv(\"HOME\") + \"/Code/Exploration Submit/5/test\"\n",
    "(x_test, y_test)=load_data(test_image_dir_path)\n",
    "x_test_norm = x_test/255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "제대로 되었는지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28, 3)\n",
      "라벨:  1\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_test_norm[150])\n",
    "print(x_test_norm[0].shape)\n",
    "print('라벨: ', y_test[150])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "evaluate 해서 test_accurcay를 구해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 0s - loss: 2.7068 - accuracy: 0.3167 - 133ms/epoch - 13ms/step\n",
      "test_loss: 2.7067670822143555 \n",
      "test_accuracy: 0.3166666626930237\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(x_test_norm, y_test, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 더 나은 모델 설정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정확도가 너무 낮으니 하이퍼 파라미터를 바꿔봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RPS_predict(n_channel_1 = 16, n_channel_2=32 , n_dense=32, n_train_epoch=10):\n",
    "    model=keras.models.Sequential()\n",
    "    model.add(keras.layers.Conv2D(n_channel_1, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "    model.add(keras.layers.MaxPool2D(2,2))\n",
    "    model.add(keras.layers.Conv2D(n_channel_2, (3,3), activation='relu'))\n",
    "    model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(n_dense, activation='relu'))\n",
    "    model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "    # model.summary()\n",
    "    model.compile(optimizer='adam',\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "    # 모델 훈련 \n",
    "    model.fit(x_train_norm, y_train, epochs=n_train_epoch, verbose = 1)\n",
    "\n",
    "    # 모델 시험\n",
    "    test_loss, test_accuracy = model.evaluate(x_test_norm, y_test, verbose=0)\n",
    "    print(n_channel_1, n_channel_2, n_dense, n_train_epoch, \": test_loss: {} \".format(test_loss))\n",
    "    print(n_channel_1, n_channel_2, n_dense, n_train_epoch, \": test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.0804 - accuracy: 0.4100\n",
      "Epoch 2/12\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.0527 - accuracy: 0.6667\n",
      "Epoch 3/12\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.0032 - accuracy: 0.8167\n",
      "Epoch 4/12\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.9494 - accuracy: 0.8567\n",
      "Epoch 5/12\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.8557 - accuracy: 0.8200\n",
      "Epoch 6/12\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.7377 - accuracy: 0.8967\n",
      "Epoch 7/12\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.6326 - accuracy: 0.7867\n",
      "Epoch 8/12\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.4847 - accuracy: 0.9133\n",
      "Epoch 9/12\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.3914 - accuracy: 0.9333\n",
      "Epoch 10/12\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.3325 - accuracy: 0.9167\n",
      "Epoch 11/12\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.2690 - accuracy: 0.9567\n",
      "Epoch 12/12\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2448 - accuracy: 0.9367\n",
      "8 16 8 12 : test_loss: 1.9747872352600098 \n",
      "8 16 8 12 : test_accuracy: 0.2800000011920929\n"
     ]
    }
   ],
   "source": [
    "RPS_predict(8,16,8,12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train 데이터의 개수가 모자란 것 같습니다.  \n",
    "train 데이터를 늘려보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여러개의 train을 사용하기위해 폴더에서 train 폴더만을 사용하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train1', 'train2', 'train3', 'train4', 'train5', 'train6']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from os import listdir\n",
    "\n",
    "list_dir = listdir('/home/aiffel/Code/Exploration Submit/5')\n",
    "list_train = []\n",
    "# print(list_dir)\n",
    "for folder in sorted(list_dir):\n",
    "    if(folder.startswith('train')):\n",
    "        list_train.append(folder)\n",
    "\n",
    "list_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100  images to be resized.\n",
      "100  images resized.\n",
      "100  images to be resized.\n",
      "100  images resized.\n",
      "100  images to be resized.\n",
      "100  images resized.\n",
      "100  images to be resized.\n",
      "100  images resized.\n",
      "100  images to be resized.\n",
      "100  images resized.\n",
      "100  images to be resized.\n",
      "100  images resized.\n",
      "100  images to be resized.\n",
      "100  images resized.\n",
      "100  images to be resized.\n",
      "100  images resized.\n",
      "100  images to be resized.\n",
      "100  images resized.\n",
      "100  images to be resized.\n",
      "100  images resized.\n",
      "100  images to be resized.\n",
      "100  images resized.\n",
      "100  images to be resized.\n",
      "100  images resized.\n",
      "100  images to be resized.\n",
      "100  images resized.\n",
      "100  images to be resized.\n",
      "100  images resized.\n",
      "100  images to be resized.\n",
      "100  images resized.\n",
      "100  images to be resized.\n",
      "100  images resized.\n",
      "100  images to be resized.\n",
      "100  images resized.\n",
      "100  images to be resized.\n",
      "100  images resized.\n"
     ]
    }
   ],
   "source": [
    "list_name = ['scissor', 'rock', 'paper']\n",
    "\n",
    "for i in list_train:\n",
    "    for j in list_name:\n",
    "        image_dir_path = os.getenv(\"HOME\") + \"/Code/Exploration Submit/5/\" + i + \"/\"+ j\n",
    "        # print(image_dir_path)\n",
    "        resize_images(image_dir_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # train 2\n",
    "# image_dir_path2_1 = os.getenv(\"HOME\") + \"/Code/Exploration Submit/5/train2/scissor\"\n",
    "# resize_images(image_dir_path2_1)\n",
    "# image_dir_path2_2 = os.getenv(\"HOME\") + \"/Code/Exploration Submit/5/train2/rock\"\n",
    "# resize_images(image_dir_path2_2)\n",
    "# image_dir_path2_3 = os.getenv(\"HOME\") + \"/Code/Exploration Submit/5/train2/paper\"\n",
    "# resize_images(image_dir_path2_3)\n",
    "\n",
    "# # train 3\n",
    "# image_dir_path3_1 = os.getenv(\"HOME\") + \"/Code/Exploration Submit/5/train3/scissor\"\n",
    "# resize_images(image_dir_path3_1)\n",
    "# image_dir_path3_2 = os.getenv(\"HOME\") + \"/Code/Exploration Submit/5/train3/rock\"\n",
    "# resize_images(image_dir_path3_2)\n",
    "# image_dir_path3_3 = os.getenv(\"HOME\") + \"/Code/Exploration Submit/5/train3/paper\"\n",
    "# resize_images(image_dir_path3_3)\n",
    "\n",
    "# # train 4\n",
    "# image_dir_path4_1 = os.getenv(\"HOME\") + \"/Code/Exploration Submit/5/train4/scissor\"\n",
    "# resize_images(image_dir_path4_1)\n",
    "# image_dir_path4_2 = os.getenv(\"HOME\") + \"/Code/Exploration Submit/5/train4/rock\"\n",
    "# resize_images(image_dir_path4_2)\n",
    "# image_dir_path4_3 = os.getenv(\"HOME\") + \"/Code/Exploration Submit/5/train4/paper\"\n",
    "# resize_images(image_dir_path4_3)\n",
    "\n",
    "# # train 5\n",
    "# image_dir_path5_1 = os.getenv(\"HOME\") + \"/Code/Exploration Submit/5/train5/scissor\"\n",
    "# resize_images(image_dir_path5_1)\n",
    "# image_dir_path5_2 = os.getenv(\"HOME\") + \"/Code/Exploration Submit/5/train5/rock\"\n",
    "# resize_images(image_dir_path5_2)\n",
    "# image_dir_path5_3 = os.getenv(\"HOME\") + \"/Code/Exploration Submit/5/train5/paper\"\n",
    "# resize_images(image_dir_path5_3)\n",
    "\n",
    "# # train 6\n",
    "# image_dir_path6_1 = os.getenv(\"HOME\") + \"/Code/Exploration Submit/5/train6/scissor\"\n",
    "# resize_images(image_dir_path6_1)\n",
    "# image_dir_path6_2 = os.getenv(\"HOME\") + \"/Code/Exploration Submit/5/train6/rock\"\n",
    "# resize_images(image_dir_path6_2)\n",
    "# image_dir_path6_3 = os.getenv(\"HOME\") + \"/Code/Exploration Submit/5/train6/paper\"\n",
    "# resize_images(image_dir_path6_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "\n",
    "# 실제 경로 = /home/aiffel/Code/Exploration Submit/5/train2/paper\n",
    "# img_path  = /Code/Exploration Submit\n",
    "# list_train = ['train1', 'train2', 'train3', 'train4', 'train5', 'train6']\n",
    "# list_name = ['scissor', 'rock', 'paper']\n",
    "def new_load_data(img_path, number_of_data=1800):  # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "    idx = 0\n",
    "    \n",
    "    for i in list_train:\n",
    "        for nidx, name in enumerate(list_name):\n",
    "            print(i, nidx, name)\n",
    "            for file in glob.iglob(img_path + \"/\" + i + \"/\" + name + \"/*.jpg\"):\n",
    "                img = np.array(Image.open(file),dtype=np.int32)\n",
    "                imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "                labels[idx] = nidx  # 가위 : 0, 바위 : 1, 보 : 2\n",
    "                idx=idx+1\n",
    "    print(\"학습데이터(x_train)의 이미지 개수는\", idx,\"입니다.\")\n",
    "    return imgs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def new_load_data(img_path1, img_path2, img_path3, img_path4, img_path5, img_path6, number_of_data=1800):  # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "#     # 가위 : 0, 바위 : 1, 보 : 2\n",
    "#     img_size=28\n",
    "#     color=3\n",
    "#     #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "#     imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "#     labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "    \n",
    "#     idx=0\n",
    "#     # train1 가위\n",
    "#     for file in glob.iglob(img_path1+'/scissor/*.jpg'):\n",
    "#         img = np.array(Image.open(file),dtype=np.int32)\n",
    "#         imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "#         labels[idx]=0   # 가위 : 0\n",
    "#         idx=idx+1\n",
    "#     # train2 가위\n",
    "#     for file in glob.iglob(img_path2+'/scissor/*.jpg'):\n",
    "#         img = np.array(Image.open(file),dtype=np.int32)\n",
    "#         imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "#         labels[idx]=0   # 가위 : 0\n",
    "#         idx=idx+1\n",
    "#     # train3 가위\n",
    "#     for file in glob.iglob(img_path3+'/scissor/*.jpg'):\n",
    "#         img = np.array(Image.open(file),dtype=np.int32)\n",
    "#         imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "#         labels[idx]=0   # 가위 : 0\n",
    "#         idx=idx+1\n",
    "#     # train4 가위\n",
    "#     for file in glob.iglob(img_path4+'/scissor/*.jpg'):\n",
    "#         img = np.array(Image.open(file),dtype=np.int32)\n",
    "#         imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "#         labels[idx]=0   # 가위 : 0\n",
    "#         idx=idx+1\n",
    "#     # train5 가위\n",
    "#     for file in glob.iglob(img_path5+'/scissor/*.jpg'):\n",
    "#         img = np.array(Image.open(file),dtype=np.int32)\n",
    "#         imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "#         labels[idx]=0   # 가위 : 0\n",
    "#         idx=idx+1\n",
    "#     # train6 가위\n",
    "#     for file in glob.iglob(img_path6+'/scissor/*.jpg'):\n",
    "#         img = np.array(Image.open(file),dtype=np.int32)\n",
    "#         imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "#         labels[idx]=0   # 가위 : 0\n",
    "#         idx=idx+1\n",
    "        \n",
    "#     # train1 바위\n",
    "#     for file in glob.iglob(img_path1+'/rock/*.jpg'):\n",
    "#         img = np.array(Image.open(file),dtype=np.int32)\n",
    "#         imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "#         labels[idx]=1   # 바위 : 1\n",
    "#         idx=idx+1\n",
    "#     # train2 바위\n",
    "#     for file in glob.iglob(img_path2+'/rock/*.jpg'):\n",
    "#         img = np.array(Image.open(file),dtype=np.int32)\n",
    "#         imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "#         labels[idx]=1   # 바위 : 1\n",
    "#         idx=idx+1 \n",
    "#     # train3 바위\n",
    "#     for file in glob.iglob(img_path3+'/rock/*.jpg'):\n",
    "#         img = np.array(Image.open(file),dtype=np.int32)\n",
    "#         imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "#         labels[idx]=1   # 바위 : 1\n",
    "#         idx=idx+1  \n",
    "#     # train4 바위\n",
    "#     for file in glob.iglob(img_path4+'/rock/*.jpg'):\n",
    "#         img = np.array(Image.open(file),dtype=np.int32)\n",
    "#         imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "#         labels[idx]=1   # 바위 : 1\n",
    "#         idx=idx+1\n",
    "#     # train5 바위\n",
    "#     for file in glob.iglob(img_path5+'/rock/*.jpg'):\n",
    "#         img = np.array(Image.open(file),dtype=np.int32)\n",
    "#         imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "#         labels[idx]=1   # 바위 : 1\n",
    "#         idx=idx+1\n",
    "#     # train6 바위\n",
    "#     for file in glob.iglob(img_path6+'/rock/*.jpg'):\n",
    "#         img = np.array(Image.open(file),dtype=np.int32)\n",
    "#         imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "#         labels[idx]=1   # 바위 : 1\n",
    "#         idx=idx+1\n",
    "        \n",
    "#     # trian1 보\n",
    "#     for file in glob.iglob(img_path1+'/paper/*.jpg'):\n",
    "#         img = np.array(Image.open(file),dtype=np.int32)\n",
    "#         imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "#         labels[idx]=2   # 보 : 2\n",
    "#         idx=idx+1\n",
    "#     # trian2 보\n",
    "#     for file in glob.iglob(img_path2+'/paper/*.jpg'):\n",
    "#         img = np.array(Image.open(file),dtype=np.int32)\n",
    "#         imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "#         labels[idx]=2   # 보 : 2\n",
    "#         idx=idx+1\n",
    "#     # trian3 보\n",
    "#     for file in glob.iglob(img_path3+'/paper/*.jpg'):\n",
    "#         img = np.array(Image.open(file),dtype=np.int32)\n",
    "#         imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "#         labels[idx]=2   # 보 : 2\n",
    "#         idx=idx+1\n",
    "#     # trn4 보\n",
    "#     for file in glob.iglob(img_path4+'/paper/*.jpg'):\n",
    "#         img = np.array(Image.open(file),dtype=np.int32)\n",
    "#         imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "#         labels[idx]=2   # 보 : 2\n",
    "#         idx=idx+1\n",
    "#     # trian5 보\n",
    "#     for file in glob.iglob(img_path5+'/paper/*.jpg'):\n",
    "#         img = np.array(Image.open(file),dtype=np.int32)\n",
    "#         imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "#         labels[idx]=2   # 보 : 2\n",
    "#         idx=idx+1    \n",
    "#     # trian6 보    \n",
    "#     for file in glob.iglob(img_path6+'/paper/*.jpg'):\n",
    "#         img = np.array(Image.open(file),dtype=np.int32)\n",
    "#         imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "#         labels[idx]=2   # 보 : 2\n",
    "#         idx=idx+1\n",
    "    \n",
    "#     print(\"학습데이터(x_train)의 이미지 개수는\", idx,\"입니다.\")\n",
    "#     return imgs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_path1 = os.getenv(\"HOME\") + \"/Code/Exploration Submit/5/train1\"\n",
    "# img_path2 = os.getenv(\"HOME\") + \"/Code/Exploration Submit/5/train2\"\n",
    "# img_path3 = os.getenv(\"HOME\") + \"/Code/Exploration Submit/5/train3\"\n",
    "# img_path4 = os.getenv(\"HOME\") + \"/Code/Exploration Submit/5/train4\"\n",
    "# img_path5 = os.getenv(\"HOME\") + \"/Code/Exploration Submit/5/train5\"\n",
    "# img_path6 = os.getenv(\"HOME\") + \"/Code/Exploration Submit/5/train6\"\n",
    "\n",
    "# (x_train, y_train)=new_load_data(img_path1, img_path2, img_path3, img_path4, img_path5, img_path6, 1800)\n",
    "# x_train_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "# print(\"x_train shape: {}\".format(x_train_norm.shape))\n",
    "# print(\"y_train shape: {}\".format(y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train1 0 scissor\n",
      "train1 1 rock\n",
      "train1 2 paper\n",
      "train2 0 scissor\n",
      "train2 1 rock\n",
      "train2 2 paper\n",
      "train3 0 scissor\n",
      "train3 1 rock\n",
      "train3 2 paper\n",
      "train4 0 scissor\n",
      "train4 1 rock\n",
      "train4 2 paper\n",
      "train5 0 scissor\n",
      "train5 1 rock\n",
      "train5 2 paper\n",
      "train6 0 scissor\n",
      "train6 1 rock\n",
      "train6 2 paper\n",
      "학습데이터(x_train)의 이미지 개수는 1800 입니다.\n",
      "x_train shape: (1800, 28, 28, 3)\n",
      "y_train shape: (1800,)\n"
     ]
    }
   ],
   "source": [
    "img_path = os.getenv(\"HOME\") + \"/Code/Exploration Submit/5/\"\n",
    "(x_train, y_train)=new_load_data(img_path, 1800)\n",
    "x_train_norm = x_train/255.0   # RPS_predict(32,32,64,14)입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_train shape: {}\".format(x_train_norm.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다시 구해봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "57/57 [==============================] - 1s 7ms/step - loss: 1.0729 - accuracy: 0.4261\n",
      "Epoch 2/10\n",
      "57/57 [==============================] - 0s 6ms/step - loss: 0.9589 - accuracy: 0.5717\n",
      "Epoch 3/10\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7273 - accuracy: 0.7494\n",
      "Epoch 4/10\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.5574 - accuracy: 0.7933\n",
      "Epoch 5/10\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.4492 - accuracy: 0.8333\n",
      "Epoch 6/10\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.3635 - accuracy: 0.8683\n",
      "Epoch 7/10\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.3226 - accuracy: 0.8844\n",
      "Epoch 8/10\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.2682 - accuracy: 0.9094\n",
      "Epoch 9/10\n",
      "57/57 [==============================] - 0s 6ms/step - loss: 0.2251 - accuracy: 0.9294\n",
      "Epoch 10/10\n",
      "57/57 [==============================] - 0s 6ms/step - loss: 0.2046 - accuracy: 0.9339\n",
      "16 16 32 10 : test_loss: 1.114546298980713 \n",
      "16 16 32 10 : test_accuracy: 0.6000000238418579\n",
      "Epoch 1/14\n",
      "57/57 [==============================] - 1s 6ms/step - loss: 1.0799 - accuracy: 0.4056\n",
      "Epoch 2/14\n",
      "57/57 [==============================] - 0s 6ms/step - loss: 0.9691 - accuracy: 0.5600\n",
      "Epoch 3/14\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.8277 - accuracy: 0.6339\n",
      "Epoch 4/14\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.6857 - accuracy: 0.7183\n",
      "Epoch 5/14\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.5743 - accuracy: 0.7789\n",
      "Epoch 6/14\n",
      "57/57 [==============================] - 0s 6ms/step - loss: 0.4769 - accuracy: 0.8261\n",
      "Epoch 7/14\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.3917 - accuracy: 0.8594\n",
      "Epoch 8/14\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.3414 - accuracy: 0.8800\n",
      "Epoch 9/14\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.2937 - accuracy: 0.8950\n",
      "Epoch 10/14\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.2420 - accuracy: 0.9200\n",
      "Epoch 11/14\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.1980 - accuracy: 0.9389\n",
      "Epoch 12/14\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.1703 - accuracy: 0.9506\n",
      "Epoch 13/14\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.1609 - accuracy: 0.9450\n",
      "Epoch 14/14\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.1389 - accuracy: 0.9600\n",
      "16 16 32 14 : test_loss: 1.7034575939178467 \n",
      "16 16 32 14 : test_accuracy: 0.5633333325386047\n",
      "Epoch 1/18\n",
      "57/57 [==============================] - 1s 7ms/step - loss: 1.0379 - accuracy: 0.4989\n",
      "Epoch 2/18\n",
      "57/57 [==============================] - 0s 6ms/step - loss: 0.7855 - accuracy: 0.7167\n",
      "Epoch 3/18\n",
      "57/57 [==============================] - 0s 6ms/step - loss: 0.5299 - accuracy: 0.8200\n",
      "Epoch 4/18\n",
      "57/57 [==============================] - 0s 6ms/step - loss: 0.4036 - accuracy: 0.8689\n",
      "Epoch 5/18\n",
      "57/57 [==============================] - 0s 6ms/step - loss: 0.3127 - accuracy: 0.9067\n",
      "Epoch 6/18\n",
      "57/57 [==============================] - 0s 6ms/step - loss: 0.2538 - accuracy: 0.9211\n",
      "Epoch 7/18\n",
      "57/57 [==============================] - 0s 6ms/step - loss: 0.1982 - accuracy: 0.9433\n",
      "Epoch 8/18\n",
      "57/57 [==============================] - 0s 6ms/step - loss: 0.1570 - accuracy: 0.9617\n",
      "Epoch 9/18\n",
      "57/57 [==============================] - 0s 6ms/step - loss: 0.1317 - accuracy: 0.9644\n",
      "Epoch 10/18\n",
      "57/57 [==============================] - 0s 6ms/step - loss: 0.1034 - accuracy: 0.9689\n",
      "Epoch 11/18\n",
      "57/57 [==============================] - 0s 6ms/step - loss: 0.0834 - accuracy: 0.9783\n",
      "Epoch 12/18\n",
      "57/57 [==============================] - 0s 6ms/step - loss: 0.0771 - accuracy: 0.9822\n",
      "Epoch 13/18\n",
      "57/57 [==============================] - 0s 6ms/step - loss: 0.0543 - accuracy: 0.9917\n",
      "Epoch 14/18\n",
      "57/57 [==============================] - 0s 6ms/step - loss: 0.0445 - accuracy: 0.9917\n",
      "Epoch 15/18\n",
      "57/57 [==============================] - 0s 6ms/step - loss: 0.0367 - accuracy: 0.9944\n",
      "Epoch 16/18\n",
      "57/57 [==============================] - 0s 6ms/step - loss: 0.0347 - accuracy: 0.9939\n",
      "Epoch 17/18\n",
      "57/57 [==============================] - 0s 6ms/step - loss: 0.0295 - accuracy: 0.9950\n",
      "Epoch 18/18\n",
      "57/57 [==============================] - 0s 6ms/step - loss: 0.0245 - accuracy: 0.9978\n",
      "16 16 32 18 : test_loss: 2.1417288780212402 \n",
      "16 16 32 18 : test_accuracy: 0.5933333039283752\n",
      "Epoch 1/10\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.0279 - accuracy: 0.4906\n",
      "Epoch 2/10\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7070 - accuracy: 0.7250\n",
      "Epoch 3/10\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.4349 - accuracy: 0.8456\n",
      "Epoch 4/10\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.2766 - accuracy: 0.9122\n",
      "Epoch 5/10\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.2007 - accuracy: 0.9367\n",
      "Epoch 6/10\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.1249 - accuracy: 0.9650\n",
      "Epoch 7/10\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0885 - accuracy: 0.9739\n",
      "Epoch 8/10\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.0645 - accuracy: 0.9856\n",
      "Epoch 9/10\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0420 - accuracy: 0.9922\n",
      "Epoch 10/10\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.0330 - accuracy: 0.9950\n",
      "32 32 64 10 : test_loss: 1.9108343124389648 \n",
      "32 32 64 10 : test_accuracy: 0.5233333110809326\n",
      "Epoch 1/14\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 1.0295 - accuracy: 0.5089\n",
      "Epoch 2/14\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6835 - accuracy: 0.7456\n",
      "Epoch 3/14\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.4521 - accuracy: 0.8244\n",
      "Epoch 4/14\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.3480 - accuracy: 0.8789\n",
      "Epoch 5/14\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.2183 - accuracy: 0.9394\n",
      "Epoch 6/14\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.1815 - accuracy: 0.9461\n",
      "Epoch 7/14\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.1179 - accuracy: 0.9717\n",
      "Epoch 8/14\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.0942 - accuracy: 0.9778\n",
      "Epoch 9/14\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.0591 - accuracy: 0.9906\n",
      "Epoch 10/14\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.0469 - accuracy: 0.9928\n",
      "Epoch 11/14\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.0369 - accuracy: 0.9944\n",
      "Epoch 12/14\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.0286 - accuracy: 0.9956\n",
      "Epoch 13/14\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.0242 - accuracy: 0.9972\n",
      "Epoch 14/14\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.0179 - accuracy: 0.9972\n",
      "32 32 64 14 : test_loss: 1.7169502973556519 \n",
      "32 32 64 14 : test_accuracy: 0.5799999833106995\n",
      "Epoch 1/18\n",
      "57/57 [==============================] - 1s 8ms/step - loss: 1.0867 - accuracy: 0.4350\n",
      "Epoch 2/18\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.9062 - accuracy: 0.6078\n",
      "Epoch 3/18\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.5770 - accuracy: 0.7956\n",
      "Epoch 4/18\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.3919 - accuracy: 0.8539\n",
      "Epoch 5/18\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.2814 - accuracy: 0.9106\n",
      "Epoch 6/18\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.2198 - accuracy: 0.9300\n",
      "Epoch 7/18\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.1638 - accuracy: 0.9561\n",
      "Epoch 8/18\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.1226 - accuracy: 0.9650\n",
      "Epoch 9/18\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.0835 - accuracy: 0.9806\n",
      "Epoch 10/18\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.0814 - accuracy: 0.9778\n",
      "Epoch 11/18\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.0607 - accuracy: 0.9872\n",
      "Epoch 12/18\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.0455 - accuracy: 0.9900\n",
      "Epoch 13/18\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.0403 - accuracy: 0.9928\n",
      "Epoch 14/18\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.0320 - accuracy: 0.9939\n",
      "Epoch 15/18\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.0253 - accuracy: 0.9956\n",
      "Epoch 16/18\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.0368 - accuracy: 0.9906\n",
      "Epoch 17/18\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.0172 - accuracy: 0.9972\n",
      "Epoch 18/18\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.0134 - accuracy: 0.9983\n",
      "32 32 64 18 : test_loss: 4.248847961425781 \n",
      "32 32 64 18 : test_accuracy: 0.41333332657814026\n"
     ]
    }
   ],
   "source": [
    "# 16 32, 16 32, 32 64, 10 13 16\n",
    "\n",
    "for i in range(1,3):\n",
    "    for j in range(10, 20, 4):\n",
    "        RPS_predict(16*i,16*i,32*i, j)\n",
    "        # print(i, j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "accuracy가 0.603이 나왔습니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
