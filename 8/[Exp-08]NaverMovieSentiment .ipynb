{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Exp-08]NaverMovieSentiment "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 라이브러리 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4.3\n",
      "0.6.0\n",
      "4.2.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import konlpy\n",
    "import gensim\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "\n",
    "print(pd.__version__)\n",
    "print(konlpy.__version__)\n",
    "print(gensim.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow GPU 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-18 21:36:49.648800: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\n",
      "2022-08-18 21:36:49.648828: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: aiffel-GE75-Raider-10SF\n",
      "2022-08-18 21:36:49.648833: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: aiffel-GE75-Raider-10SF\n",
      "2022-08-18 21:36:49.648919: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 510.85.2\n",
      "2022-08-18 21:36:49.648935: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 510.85.2\n",
      "2022-08-18 21:36:49.648939: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 510.85.2\n",
      "2022-08-18 21:36:49.650052: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 18080274224392936032\n",
       " xla_global_id: -1]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 불러오기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naver sentiment movie corpus](https://github.com/e9t/nsmc)\n",
    "* id : 네이버 아이디\n",
    "* document : 실제 리뷰 내용\n",
    "* label : 감성(0: 부정, 1: 긍정)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9976970</td>\n",
       "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3819312</td>\n",
       "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10265843</td>\n",
       "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9045019</td>\n",
       "      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6483659</td>\n",
       "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document  label\n",
       "0   9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n",
       "1   3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
       "2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
       "3   9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
       "4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6270596</td>\n",
       "      <td>굳 ㅋ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9274899</td>\n",
       "      <td>GDNTOPCLASSINTHECLUB</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8544678</td>\n",
       "      <td>뭐야 이 평점들은.... 나쁘진 않지만 10점 짜리는 더더욱 아니잖아</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6825595</td>\n",
       "      <td>지루하지는 않은데 완전 막장임... 돈주고 보기에는....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6723715</td>\n",
       "      <td>3D만 아니었어도 별 다섯 개 줬을텐데.. 왜 3D로 나와서 제 심기를 불편하게 하죠??</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                           document  label\n",
       "0  6270596                                                굳 ㅋ      1\n",
       "1  9274899                               GDNTOPCLASSINTHECLUB      0\n",
       "2  8544678             뭐야 이 평점들은.... 나쁘진 않지만 10점 짜리는 더더욱 아니잖아      0\n",
       "3  6825595                   지루하지는 않은데 완전 막장임... 돈주고 보기에는....      0\n",
       "4  6723715  3D만 아니었어도 별 다섯 개 줬을텐데.. 왜 3D로 나와서 제 심기를 불편하게 하죠??      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data = pd.read_table('data/ratings_train.txt')\n",
    "test_data = pd.read_table('data/ratings_test.txt')\n",
    "\n",
    "display(train_data.head())\n",
    "display(test_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150000, 3)\n",
      "2\n",
      "0\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150000 entries, 0 to 149999\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count   Dtype \n",
      "---  ------    --------------   ----- \n",
      " 0   id        150000 non-null  int64 \n",
      " 1   document  149995 non-null  object\n",
      " 2   label     150000 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 3.4+ MB\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape)\n",
    "print(len(train_data.label.unique()))\n",
    "print(train_data.duplicated().sum())\n",
    "train_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* train 데이터는 15만개, 3개의 열을 가지고 있습니다.\n",
    "* label의 uniuqe가 2개니 0,1 값만 가지고 있는게 맞습니다.\n",
    "* document에서 null value를 가지고 있습니다.\n",
    "* dtype은 document는 object이며(아마 string 같습니다.) 나머진 int 값입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 3)\n",
      "2\n",
      "0\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id        50000 non-null  int64 \n",
      " 1   document  49997 non-null  object\n",
      " 2   label     50000 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "print(test_data.shape)\n",
    "print(len(test_data.label.unique()))\n",
    "print(test_data.duplicated().sum())\n",
    "test_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* test 데이터도 5만개, 3개의 열을 가지고 있습니다.\n",
    "* 나머지 특징은 train과 같습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 로더 구성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Mecab 사용법](https://konlpy-ko.readthedocs.io/ko/v0.4.3/api/konlpy.tag/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Mecab\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "tokenizer = Mecab()\n",
    "stopwords = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다']\n",
    "\n",
    "def load_data(train_data, test_data, num_words = 10000):\n",
    "    # 중복 값 제거\n",
    "    train_data.drop_duplicates(subset=['document'], inplace=True)\n",
    "    train_data = train_data.dropna(how = 'any') \n",
    "    test_data.drop_duplicates(subset=['document'], inplace=True)\n",
    "    test_data = test_data.dropna(how = 'any') \n",
    "    \n",
    "    # Mecab의 morphs가 string 단위로 읽어오기 때문에\n",
    "    # 문장으로 받은 뒤 단어를 보면서 불용어인 경우에는 넣지 않습니다.\n",
    "    X_train = []\n",
    "    for sentence in train_data['document']:\n",
    "        temp_X = tokenizer.morphs(sentence)\n",
    "        temp_X = [word for word in temp_X if not word in stopwords]\n",
    "        X_train.append(temp_X)\n",
    "\n",
    "    X_test = []\n",
    "    for sentence in test_data['document']:\n",
    "        temp_X = tokenizer.morphs(sentence)\n",
    "        temp_X = [word for word in temp_X if not word in stopwords]\n",
    "        X_test.append(temp_X)\n",
    "    \n",
    "    # 문장들을 연결한뒤 리스트로 바꿔줍니다.\n",
    "    words = np.concatenate(X_train).tolist()\n",
    "    # 리스트의 요소와 개수를 \n",
    "    counter = Counter(words)\n",
    "    # 가장 많이 나온 것들 중들에서 (사용할 단어 - 4)개 만큼 가져온다.\n",
    "    counter = counter.most_common(num_words - 4)\n",
    "    # 단어 리스트를 만듭니다.\n",
    "    vocab = ['<PAD>', '<BOS>', '<UNK>', '<UNUSED>'] + [key for key, _ in counter]\n",
    "    # 단어:index로 이루어진 딕셔너리를 만듭니다.\n",
    "    word_to_index = {word:index for index, word in enumerate(vocab)}\n",
    "    \n",
    "    # wordlist를 indexlist로 바꾸는 함수입니다.(단어사전에 없으면 2(<UNK> 인덱스)를 넣습니다.)\n",
    "    def wordlist_to_indexlist(wordlist):\n",
    "        return [word_to_index[word] if word in word_to_index else word_to_index['<UNK>'] for word in wordlist]\n",
    "    \n",
    "    X_train = list(map(wordlist_to_indexlist, X_train))\n",
    "    X_test = list(map(wordlist_to_indexlist, X_test))\n",
    "    \n",
    "    return X_train, np.array(list(train_data['label'])), X_test, np.array(list(test_data['label'])), word_to_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test, word_to_index = load_data(train_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_word = {index:word for word, index in word_to_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장 1개를 활용할 딕셔너리와 함께 주면, 단어 인덱스 리스트 벡터로 변환해 주는 함수입니다. \n",
    "# 단, 모든 문장은 <BOS>로 시작하는 것으로 합니다. \n",
    "def get_encoded_sentence(sentence, word_to_index):\n",
    "    return [word_to_index['<BOS>']]+[word_to_index[word] if word in word_to_index else word_to_index['<UNK>'] for word in sentence.split()]\n",
    "\n",
    "# 여러 개의 문장 리스트를 한꺼번에 단어 인덱스 리스트 벡터로 encode해 주는 함수입니다. \n",
    "def get_encoded_sentences(sentences, word_to_index):\n",
    "    return [get_encoded_sentence(sentence, word_to_index) for sentence in sentences]\n",
    "\n",
    "# 숫자 벡터로 encode된 문장을 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentence(encoded_sentence, index_to_word):\n",
    "    return ' '.join(index_to_word[index] if index in index_to_word else '<UNK>' for index in encoded_sentence[1:])  #[1:]를 통해 <BOS>를 제외\n",
    "\n",
    "# 여러 개의 숫자 벡터로 encode된 문장을 한꺼번에 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentences(encoded_sentences, index_to_word):\n",
    "    return [get_decoded_sentence(encoded_sentence, index_to_word) for encoded_sentence in encoded_sentences]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 구성을 위한 데이터 분석 및 가공"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> <class 'list'>\n",
      "146182 49157\n",
      "[32, 74, 919, 4, 4, 39, 228, 20, 33, 748]\n",
      "[832, 130]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "146182 49157\n",
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(type(X_train), type(X_test))\n",
    "print(len(X_train), len(X_test))\n",
    "print(X_train[0])\n",
    "print(X_test[0])\n",
    "print(type(y_train), type(y_test))\n",
    "print(len(y_train), len(y_test))\n",
    "print(y_train[0])\n",
    "print(y_test[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터셋 내 문장 길이 분포"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/aiffel/Code/Exploration_Submit/8/[Exp-08]NaverMovieSentiment .ipynb 셀 22\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/aiffel/Code/Exploration_Submit/8/%5BExp-08%5DNaverMovieSentiment%20.ipynb#X30sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m total_train_data \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(X_train) \u001b[39m+\u001b[39m \u001b[39mlist\u001b[39m(X_test)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/aiffel/Code/Exploration_Submit/8/%5BExp-08%5DNaverMovieSentiment%20.ipynb#X30sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m num_tokens \u001b[39m=\u001b[39m [\u001b[39mlen\u001b[39m(tokens) \u001b[39mfor\u001b[39;00m tokens \u001b[39min\u001b[39;00m total_train_data]\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/aiffel/Code/Exploration_Submit/8/%5BExp-08%5DNaverMovieSentiment%20.ipynb#X30sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m num_tokens \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(num_tokens)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "total_train_data = list(X_train) + list(X_test)\n",
    "num_tokens = [len(tokens) for tokens in total_train_data]\n",
    "num_tokens = np.array(num_tokens)\n",
    "num_tokens_count = np.bincount(num_tokens)\n",
    "\n",
    "print('num_tokens :', num_tokens)\n",
    "print('문장길이 평균 :', np.mean(num_tokens))\n",
    "print('문장길이 중간값 :', np.median(num_tokens))\n",
    "print('문장길이 최대 :', np.max(num_tokens))\n",
    "print('문장길이 표준편차: ', np.std(num_tokens))\n",
    "print('문장길이 최빈값: ', num_tokens_count.argmax())\n",
    "\n",
    "\n",
    "plt.figure(figsize = (10,5))\n",
    "sns.histplot(num_tokens)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
